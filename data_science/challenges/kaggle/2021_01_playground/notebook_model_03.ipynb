{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['id']]\n",
    "train = train.drop(['id'], axis=1)\n",
    "test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['target']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:, train.columns != 'target']\n",
    "y_train = train[['target']]\n",
    "x_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm = GaussianMixture(n_components=2, random_state=0).fit(y_train)\n",
    "y_train2 = gm.predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class'] = y_train2\n",
    "fig = px.histogram(train, x='target', color='class', marginal=\"box\", barmode=\"overlay\", nbins=200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train2)\n",
    "pred = clf.predict(x_train)\n",
    "np.round(100.*accuracy_score(y_train2, pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "\n",
    "def run_model(X, y, X_test):\n",
    "    \"\"\"\n",
    "    Baseline is based on\n",
    "    https://www.kaggle.com/ttahara/tps-jan-2021-gbdts-baseline\n",
    "    \n",
    "    Arg:\n",
    "    * X: training data containing features\n",
    "    * y: training data containing target variables\n",
    "    * X_test: test data to predict\n",
    "    \n",
    "    Returns:\n",
    "    * predictions for X_test\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    y_oof_pred = np.zeros(len(X))\n",
    "    y_test_pred = np.zeros(len(X_test))\n",
    "\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}:\")\n",
    "\n",
    "        # Prepare training and validation data\n",
    "        X_train = X.iloc[train_idx].reset_index(drop=True)\n",
    "        X_val = X.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        y_train = y.iloc[train_idx].reset_index(drop=True)\n",
    "        y_val = y.iloc[val_idx].reset_index(drop=True)  \n",
    "\n",
    "        # Define model\n",
    "        reg = RandomForestRegressor()\n",
    "        reg.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate evaluation metric: Root Mean Squared Error (RMSE)\n",
    "        y_val_pred = reg.predict(X_val)\n",
    "        score = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        print(f\"RMSE: {score:.5f}\\n\")\n",
    "\n",
    "        y_oof_pred[val_idx] = y_val_pred\n",
    "\n",
    "        # Make predictions\n",
    "        y_test_pred += reg.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metric for out of fold validation set\n",
    "    oof_score = np.sqrt(mean_squared_error(y, y_oof_pred))\n",
    "    print(f\"OOF RMSE: {oof_score: 5f}\")\n",
    "\n",
    "    # Average predictions over all folds\n",
    "    y_test_pred = y_test_pred / N_SPLITS\n",
    "\n",
    "    return y_test_pred\n",
    "\n",
    "\n",
    "y_pred = run_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = y_pred\n",
    "test['target'] = y_pred\n",
    "train['label'] = 'train'\n",
    "test['label'] = 'test'\n",
    "df = pd.concat([train, test])\n",
    "fig = px.histogram(df, x='target', color='label', marginal=\"box\", barmode=\"overlay\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
